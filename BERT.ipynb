{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dh646956164/CS_project/blob/main/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7Q_EUYQcOOk",
        "outputId": "ba021b43-2694-4831-9880-cc1b6348d1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install tqdm\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axwqaqhd6ENN",
        "outputId": "1fb77ce2-ae1c-4754-a9a3-da41a32763d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-2-5c0f14b93dac>\", line 7, in <cell line: 7>\n",
            "    from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
            "ModuleNotFoundError: No module named 'transformers'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 878, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 396, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, strict, {})\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 431, in _joinrealpath\n",
            "    st = os.lstat(newpath)\n",
            "KeyboardInterrupt\n",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\n",
            "\u001b[0;32m<ipython-input-2-5c0f14b93dac>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell_customizations.py\u001b[0m in \u001b[0;36mhandle_error\u001b[0;34m(self, shell, etype, exception, tb, tb_offset)\u001b[0m\n",
            "\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     93\u001b[0m       \u001b[0mcustom_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 94\u001b[0;31m       structured_traceback = shell.InteractiveTB.structured_traceback(\n",
            "\u001b[0m\u001b[1;32m     95\u001b[0m           \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     96\u001b[0m       )\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n",
            "\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n",
            "\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
            "\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n",
            "\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n",
            "\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1269\u001b[0m             )\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n",
            "\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n",
            "\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n",
            "\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n",
            "\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()\n",
            "The original exception:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Custom TB Handler failed, unregistering\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. 数据加载\n",
        "df = pd.read_json(\"HAO_comment_classification.json\")\n",
        "df_cleaned = df.dropna(subset=['Comment Classification'])\n",
        "df_cleaned['Comment Classification'] = df_cleaned['Comment Classification'].astype(str).str.split(', ')\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "label_data_cleaned = mlb.fit_transform(df_cleaned['Comment Classification'])\n",
        "label_df_cleaned = pd.DataFrame(label_data_cleaned, columns=mlb.classes_)\n",
        "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(df_cleaned['Comment Body'], label_df_cleaned, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. 使用BERT的tokenizer进行tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_data(texts, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True  # Explicit truncation\n",
        "        )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_input_ids, train_attention_masks = tokenize_data(X_train_cleaned)\n",
        "test_input_ids, test_attention_masks = tokenize_data(X_test_cleaned)\n",
        "train_labels = torch.tensor(y_train_cleaned.values)\n",
        "test_labels = torch.tensor(y_test_cleaned.values)\n",
        "\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# 3. 使用BERT进行多标签分类的模型定义和训练\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(mlb.classes_))\n",
        "\n",
        "# Move the model to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "epochs = 4\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Calling model without labels\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Manually computing the loss\n",
        "        loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "        loss = loss_fn(logits, labels.float())\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        progress_bar.set_postfix({'loss': total_loss / (epoch + 1)})\n",
        "\n",
        "\n",
        "# 4. 模型评估\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "for batch in test_dataloader:\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "    labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs[0].detach().cpu().numpy()\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(labels)\n",
        "\n",
        "# ... (您可以在这里进一步处理预测结果，例如计算性能指标)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "Z3dmxBu7Wkdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57f90yf38B9X",
        "outputId": "49bcad66-f410-4a81-af4e-0b23f1a5efb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 1: 100%|██████████| 46/46 [00:30<00:00,  1.51it/s, loss=20.9]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Training loss: 0.454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 46/46 [00:28<00:00,  1.60it/s, loss=5.64]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Training loss: 0.245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 46/46 [00:28<00:00,  1.59it/s, loss=2.7]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Training loss: 0.176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 46/46 [00:29<00:00,  1.58it/s, loss=1.7]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 - Training loss: 0.147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 46/46 [00:28<00:00,  1.59it/s, loss=1.23]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 - Training loss: 0.134\n",
            "Classification Report:\n",
            "                                    precision    recall  f1-score   support\n",
            "\n",
            "Algorithmic Efficiency/Performance       0.00      0.00      0.00         1\n",
            "                   Code Complexity       0.00      0.00      0.00        14\n",
            "           Code Style & Formatting       0.00      0.00      0.00        21\n",
            "              Compatibility Issues       0.00      0.00      0.00         4\n",
            "        Data & Resource Management       0.00      0.00      0.00         1\n",
            "             Depreciated Functions       0.00      0.00      0.00         1\n",
            "                     Documentation       0.00      0.00      0.00        21\n",
            "                       Duplication       0.00      0.00      0.00         2\n",
            "                      Element Type       0.00      0.00      0.00         2\n",
            "                    Execution Time       0.00      0.00      0.00         1\n",
            "              Feature Completeness       0.00      0.00      0.00         1\n",
            "                    Function Calls       0.00      0.00      0.00         1\n",
            "               Function Parameters       0.00      0.00      0.00         1\n",
            "                   Inline Comments       0.00      0.00      0.00         3\n",
            "                  Input Validation       0.00      0.00      0.00         2\n",
            "          Issues with Outside Code       0.00      0.00      0.00         0\n",
            "                Knowledge Transfer       0.00      0.00      0.00         5\n",
            "                           Logging       0.00      0.00      0.00         4\n",
            "                       Logic Error       0.00      0.00      0.00        11\n",
            "                              Misc       0.00      0.00      0.00         3\n",
            "              Moving Functionality       0.00      0.00      0.00         6\n",
            "                Naming Conventions       0.00      0.00      0.00        19\n",
            "                Other Test related       0.00      0.00      0.00         2\n",
            "                Removing Dead Code       0.00      0.00      0.00         8\n",
            "                 Security Concerns       0.00      0.00      0.00         1\n",
            "              Social Communication       0.00      0.00      0.00         5\n",
            "                        Test Cases       0.00      0.00      0.00         1\n",
            "                     Test Coverage       0.00      0.00      0.00         4\n",
            "                     Understanding       0.00      0.00      0.00        22\n",
            "       Unhandled Errors/Exceptions       0.00      0.00      0.00         3\n",
            "               Unvalidated Element       0.00      0.00      0.00         3\n",
            "            Using standard methods       0.00      0.00      0.00         8\n",
            "           Variable Initialisation       0.00      0.00      0.00         0\n",
            "                        Visibility       0.00      0.00      0.00         2\n",
            "                    Wrong Location       0.00      0.00      0.00         1\n",
            "\n",
            "                         micro avg       0.00      0.00      0.00       184\n",
            "                         macro avg       0.00      0.00      0.00       184\n",
            "                      weighted avg       0.00      0.00      0.00       184\n",
            "                       samples avg       0.00      0.00      0.00       184\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. 数据加载\n",
        "df = pd.read_json(\"HAO_comment_classification.json\")\n",
        "df_cleaned = df.dropna(subset=['Comment Classification'])\n",
        "df_cleaned['Comment Classification'] = df_cleaned['Comment Classification'].astype(str).str.split(', ')\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "label_data_cleaned = mlb.fit_transform(df_cleaned['Comment Classification'])\n",
        "label_df_cleaned = pd.DataFrame(label_data_cleaned, columns=mlb.classes_)\n",
        "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(df_cleaned['Comment Body'], label_df_cleaned, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. 使用BERT的tokenizer进行tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_data(texts, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_input_ids, train_attention_masks = tokenize_data(X_train_cleaned)\n",
        "test_input_ids, test_attention_masks = tokenize_data(X_test_cleaned)\n",
        "train_labels = torch.tensor(y_train_cleaned.values)\n",
        "test_labels = torch.tensor(y_test_cleaned.values)\n",
        "\n",
        "# 3. DataLoader Preparation\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# 4. Model Preparation\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(mlb.classes_))\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "\n",
        "# 5. Model Training\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "    for batch in progress_bar:\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask, labels=labels.float())  # Ensure labels are float type\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        progress_bar.set_postfix({'loss': total_loss / (epoch + 1)})\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch+1} - Training loss: {avg_train_loss:.3f}\")\n",
        "\n",
        "# 6. Model Evaluation\n",
        "model.eval()\n",
        "predictions = []\n",
        "for batch in test_dataloader:\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.extend(logits)\n",
        "\n",
        "# Convert logits to labels\n",
        "pred_labels = [(np.array(pred) > 0).astype(int) for pred in predictions]\n",
        "\n",
        "# 7. Compute Metrics\n",
        "true_labels_flat = y_test_cleaned.values\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels_flat, pred_labels, target_names=mlb.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp_JGCbM6tqu",
        "outputId": "37bb9af5-d62b-44fd-ef0d-7f8beb2a644e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 1: 100%|██████████| 46/46 [00:30<00:00,  1.52it/s, loss=22.5]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Training loss: 0.488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 46/46 [00:28<00:00,  1.59it/s, loss=6.47]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Training loss: 0.281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 46/46 [00:28<00:00,  1.59it/s, loss=3.24]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Training loss: 0.211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 46/46 [00:29<00:00,  1.58it/s, loss=2.11]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 - Training loss: 0.183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 46/46 [00:28<00:00,  1.59it/s, loss=1.59]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 - Training loss: 0.173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 46/46 [00:28<00:00,  1.59it/s, loss=1.31]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 - Training loss: 0.171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 46/46 [00:28<00:00,  1.59it/s, loss=1.13]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 - Training loss: 0.171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 46/46 [00:28<00:00,  1.59it/s, loss=0.985]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 - Training loss: 0.171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 46/46 [00:29<00:00,  1.59it/s, loss=0.875]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 - Training loss: 0.171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 46/46 [00:28<00:00,  1.59it/s, loss=0.787]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 - Training loss: 0.171\n",
            "Classification Report:\n",
            "                                    precision    recall  f1-score   support\n",
            "\n",
            "Algorithmic Efficiency/Performance       0.00      0.00      0.00         1\n",
            "                   Code Complexity       0.00      0.00      0.00        14\n",
            "           Code Style & Formatting       0.00      0.00      0.00        21\n",
            "              Compatibility Issues       0.00      0.00      0.00         4\n",
            "        Data & Resource Management       0.00      0.00      0.00         1\n",
            "             Depreciated Functions       0.00      0.00      0.00         1\n",
            "                     Documentation       0.00      0.00      0.00        21\n",
            "                       Duplication       0.00      0.00      0.00         2\n",
            "                      Element Type       0.00      0.00      0.00         2\n",
            "                    Execution Time       0.00      0.00      0.00         1\n",
            "              Feature Completeness       0.00      0.00      0.00         1\n",
            "                    Function Calls       0.00      0.00      0.00         1\n",
            "               Function Parameters       0.00      0.00      0.00         1\n",
            "                   Inline Comments       0.00      0.00      0.00         3\n",
            "                  Input Validation       0.00      0.00      0.00         2\n",
            "          Issues with Outside Code       0.00      0.00      0.00         0\n",
            "                Knowledge Transfer       0.00      0.00      0.00         5\n",
            "                           Logging       0.00      0.00      0.00         4\n",
            "                       Logic Error       0.00      0.00      0.00        11\n",
            "                              Misc       0.00      0.00      0.00         3\n",
            "              Moving Functionality       0.00      0.00      0.00         6\n",
            "                Naming Conventions       0.00      0.00      0.00        19\n",
            "                Other Test related       0.00      0.00      0.00         2\n",
            "                Removing Dead Code       0.00      0.00      0.00         8\n",
            "                 Security Concerns       0.00      0.00      0.00         1\n",
            "              Social Communication       0.00      0.00      0.00         5\n",
            "                        Test Cases       0.00      0.00      0.00         1\n",
            "                     Test Coverage       0.00      0.00      0.00         4\n",
            "                     Understanding       0.00      0.00      0.00        22\n",
            "       Unhandled Errors/Exceptions       0.00      0.00      0.00         3\n",
            "               Unvalidated Element       0.00      0.00      0.00         3\n",
            "            Using standard methods       0.00      0.00      0.00         8\n",
            "           Variable Initialisation       0.00      0.00      0.00         0\n",
            "                        Visibility       0.00      0.00      0.00         2\n",
            "                    Wrong Location       0.00      0.00      0.00         1\n",
            "\n",
            "                         micro avg       0.00      0.00      0.00       184\n",
            "                         macro avg       0.00      0.00      0.00       184\n",
            "                      weighted avg       0.00      0.00      0.00       184\n",
            "                       samples avg       0.00      0.00      0.00       184\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. 数据加载\n",
        "df = pd.read_json(\"HAO_comment_classification.json\")\n",
        "df_cleaned = df.dropna(subset=['Comment Classification'])\n",
        "df_cleaned['Comment Classification'] = df_cleaned['Comment Classification'].astype(str).str.split(', ')\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "label_data_cleaned = mlb.fit_transform(df_cleaned['Comment Classification'])\n",
        "label_df_cleaned = pd.DataFrame(label_data_cleaned, columns=mlb.classes_)\n",
        "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(df_cleaned['Comment Body'], label_df_cleaned, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. 使用BERT的tokenizer进行tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_data(texts, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_input_ids, train_attention_masks = tokenize_data(X_train_cleaned)\n",
        "test_input_ids, test_attention_masks = tokenize_data(X_test_cleaned)\n",
        "train_labels = torch.tensor(y_train_cleaned.values)\n",
        "test_labels = torch.tensor(y_test_cleaned.values)\n",
        "\n",
        "# 3. DataLoader Preparation\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# 4. Model Preparation\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(mlb.classes_))\n",
        "model.config.hidden_dropout_prob = 0.5  # Add dropout\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Add learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(train_dataloader) * epochs)\n",
        "\n",
        "# 5. Model Training\n",
        "epochs = 10  # Increased epochs\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "    for batch in progress_bar:\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask, labels=labels.float())\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'loss': total_loss / (epoch + 1)})\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch+1} - Training loss: {avg_train_loss:.3f}\")\n",
        "\n",
        "# 6. Model Evaluation\n",
        "model.eval()\n",
        "predictions = []\n",
        "for batch in test_dataloader:\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.extend(logits)\n",
        "\n",
        "# Adjust decision threshold\n",
        "threshold = 0.3\n",
        "pred_labels = [(np.array(pred) > threshold).astype(int) for pred in predictions]\n",
        "\n",
        "# 7. Compute Metrics\n",
        "true_labels_flat = y_test_cleaned.values\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels_flat, pred_labels, target_names=mlb.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-FqLf93cAdr",
        "outputId": "6cf86e6d-5dd1-43df-fa93-9ea8d69e1d63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1: 100%|██████████| 46/46 [00:31<00:00,  1.46it/s, loss=26.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Training loss: 0.566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 46/46 [00:30<00:00,  1.53it/s, loss=7.76]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Training loss: 0.338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 46/46 [00:29<00:00,  1.55it/s, loss=3.29]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Training loss: 0.214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 46/46 [00:30<00:00,  1.52it/s, loss=1.89]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 - Training loss: 0.164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 46/46 [00:30<00:00,  1.52it/s, loss=1.33]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 - Training loss: 0.145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 46/46 [00:29<00:00,  1.53it/s, loss=1.04]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 - Training loss: 0.136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 46/46 [00:30<00:00,  1.52it/s, loss=0.859]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 - Training loss: 0.131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 46/46 [00:30<00:00,  1.53it/s, loss=0.74]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 - Training loss: 0.129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 46/46 [00:30<00:00,  1.52it/s, loss=0.654]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 - Training loss: 0.128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 46/46 [00:30<00:00,  1.53it/s, loss=0.588]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 - Training loss: 0.128\n",
            "Classification Report:\n",
            "                                    precision    recall  f1-score   support\n",
            "\n",
            "Algorithmic Efficiency/Performance       0.00      0.00      0.00         1\n",
            "                   Code Complexity       0.00      0.00      0.00        14\n",
            "           Code Style & Formatting       0.00      0.00      0.00        21\n",
            "              Compatibility Issues       0.00      0.00      0.00         4\n",
            "        Data & Resource Management       0.00      0.00      0.00         1\n",
            "             Depreciated Functions       0.00      0.00      0.00         1\n",
            "                     Documentation       0.00      0.00      0.00        21\n",
            "                       Duplication       0.00      0.00      0.00         2\n",
            "                      Element Type       0.00      0.00      0.00         2\n",
            "                    Execution Time       0.00      0.00      0.00         1\n",
            "              Feature Completeness       0.00      0.00      0.00         1\n",
            "                    Function Calls       0.00      0.00      0.00         1\n",
            "               Function Parameters       0.00      0.00      0.00         1\n",
            "                   Inline Comments       0.00      0.00      0.00         3\n",
            "                  Input Validation       0.00      0.00      0.00         2\n",
            "          Issues with Outside Code       0.00      0.00      0.00         0\n",
            "                Knowledge Transfer       0.00      0.00      0.00         5\n",
            "                           Logging       0.00      0.00      0.00         4\n",
            "                       Logic Error       0.00      0.00      0.00        11\n",
            "                              Misc       0.00      0.00      0.00         3\n",
            "              Moving Functionality       0.00      0.00      0.00         6\n",
            "                Naming Conventions       0.00      0.00      0.00        19\n",
            "                Other Test related       0.00      0.00      0.00         2\n",
            "                Removing Dead Code       0.00      0.00      0.00         8\n",
            "                 Security Concerns       0.00      0.00      0.00         1\n",
            "              Social Communication       0.00      0.00      0.00         5\n",
            "                        Test Cases       0.00      0.00      0.00         1\n",
            "                     Test Coverage       0.00      0.00      0.00         4\n",
            "                     Understanding       0.00      0.00      0.00        22\n",
            "       Unhandled Errors/Exceptions       0.00      0.00      0.00         3\n",
            "               Unvalidated Element       0.00      0.00      0.00         3\n",
            "            Using standard methods       0.00      0.00      0.00         8\n",
            "           Variable Initialisation       0.00      0.00      0.00         0\n",
            "                        Visibility       0.00      0.00      0.00         2\n",
            "                    Wrong Location       0.00      0.00      0.00         1\n",
            "\n",
            "                         micro avg       0.00      0.00      0.00       184\n",
            "                         macro avg       0.00      0.00      0.00       184\n",
            "                      weighted avg       0.00      0.00      0.00       184\n",
            "                       samples avg       0.00      0.00      0.00       184\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. 数据加载\n",
        "df = pd.read_json(\"HAO_comment_classification.json\")\n",
        "df_cleaned = df.dropna(subset=['Comment Classification'])\n",
        "df_cleaned['Comment Classification'] = df_cleaned['Comment Classification'].astype(str).str.split(', ')\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "label_data_cleaned = mlb.fit_transform(df_cleaned['Comment Classification'])\n",
        "label_df_cleaned = pd.DataFrame(label_data_cleaned, columns=mlb.classes_)\n",
        "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(df_cleaned['Comment Body'], label_df_cleaned, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. 使用BERT的tokenizer进行tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_data(texts, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_input_ids, train_attention_masks = tokenize_data(X_train_cleaned)\n",
        "test_input_ids, test_attention_masks = tokenize_data(X_test_cleaned)\n",
        "train_labels = torch.tensor(y_train_cleaned.values)\n",
        "test_labels = torch.tensor(y_test_cleaned.values)\n",
        "\n",
        "# 3. DataLoader Preparation\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# 4. Custom Model Preparation with additional Fully Connected Layers\n",
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.classifier[-1].out_features), labels.view(-1, self.classifier[-1].out_features).float())\n",
        "        return loss, logits\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomBERTModel(num_labels=len(mlb.classes_))\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Add learning rate scheduler\n",
        "epochs = 10\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * epochs)\n",
        "\n",
        "# 5. Model Training\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "    for batch in progress_bar:\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss, logits = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'loss': total_loss / (epoch + 1)})\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch+1} - Training loss: {avg_train_loss:.3f}\")\n",
        "\n",
        "# 6. Model Evaluation\n",
        "model.eval()\n",
        "predictions = []\n",
        "for batch in test_dataloader:\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loss, logits = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.extend(logits)\n",
        "\n",
        "# Adjust decision threshold\n",
        "threshold = 0.3\n",
        "pred_labels = [(np.array(pred) > threshold).astype(int) for pred in predictions]\n",
        "\n",
        "# 7. Compute Metrics\n",
        "true_labels_flat = y_test_cleaned.values\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels_flat, pred_labels, target_names=mlb.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1y9G4bb1cA2g",
        "outputId": "6802e357-7f4d-4504-93db-8d11b8dec91b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial size: 904\n",
            "Size after dropping NA: 904\n",
            "Size after category filtering: 901\n",
            "(901, 8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1: 100%|██████████| 45/45 [00:10<00:00,  4.30it/s, loss=120]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Training loss: 2.656, Training accuracy: 0.14, Test accuracy: 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 45/45 [00:10<00:00,  4.35it/s, loss=53]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Training loss: 2.356, Training accuracy: 0.24, Test accuracy: 0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 45/45 [00:10<00:00,  4.34it/s, loss=32.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Training loss: 2.185, Training accuracy: 0.33, Test accuracy: 0.35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 45/45 [00:10<00:00,  4.34it/s, loss=22.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Training loss: 1.961, Training accuracy: 0.42, Test accuracy: 0.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 45/45 [00:10<00:00,  4.36it/s, loss=15.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Training loss: 1.674, Training accuracy: 0.55, Test accuracy: 0.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 45/45 [00:10<00:00,  4.34it/s, loss=10.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Training loss: 1.392, Training accuracy: 0.63, Test accuracy: 0.43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 45/45 [00:10<00:00,  4.34it/s, loss=7.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Training loss: 1.129, Training accuracy: 0.69, Test accuracy: 0.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 45/45 [00:10<00:00,  4.34it/s, loss=5.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Training loss: 0.958, Training accuracy: 0.74, Test accuracy: 0.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 45/45 [00:10<00:00,  4.33it/s, loss=3.96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Training loss: 0.791, Training accuracy: 0.80, Test accuracy: 0.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 45/45 [00:10<00:00,  4.34it/s, loss=2.95]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Training loss: 0.655, Training accuracy: 0.87, Test accuracy: 0.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 45/45 [00:10<00:00,  4.34it/s, loss=2.31]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Training loss: 0.566, Training accuracy: 0.89, Test accuracy: 0.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 45/45 [00:10<00:00,  4.35it/s, loss=1.85]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Training loss: 0.493, Training accuracy: 0.91, Test accuracy: 0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 45/45 [00:10<00:00,  4.34it/s, loss=1.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 - Training loss: 0.437, Training accuracy: 0.93, Test accuracy: 0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 45/45 [00:10<00:00,  4.36it/s, loss=1.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 - Training loss: 0.393, Training accuracy: 0.94, Test accuracy: 0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 45/45 [00:10<00:00,  4.34it/s, loss=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 - Training loss: 0.362, Training accuracy: 0.94, Test accuracy: 0.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 45/45 [00:10<00:00,  4.33it/s, loss=0.938]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 - Training loss: 0.333, Training accuracy: 0.95, Test accuracy: 0.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 45/45 [00:10<00:00,  4.35it/s, loss=0.854]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 - Training loss: 0.323, Training accuracy: 0.96, Test accuracy: 0.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 45/45 [00:10<00:00,  4.34it/s, loss=0.756]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 - Training loss: 0.302, Training accuracy: 0.96, Test accuracy: 0.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 45/45 [00:10<00:00,  4.35it/s, loss=0.695]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 - Training loss: 0.294, Training accuracy: 0.97, Test accuracy: 0.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 45/45 [00:10<00:00,  4.34it/s, loss=0.642]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 - Training loss: 0.285, Training accuracy: 0.97, Test accuracy: 0.48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. 数据加载\n",
        "df = pd.read_json(\"HAO_comment_classification.json\")\n",
        "print(f\"Initial size: {len(df)}\")\n",
        "\n",
        "df_cleaned = df.dropna(subset=['Comment Classification'])\n",
        "print(f\"Size after dropping NA: {len(df_cleaned)}\")\n",
        "\n",
        "# Transform multi-label to single label\n",
        "df_cleaned['SingleLabel'] = df_cleaned['Comment Classification'].apply(lambda x: x[0])\n",
        "\n",
        "# 保留在38个类别中的标签\n",
        "categories = [\n",
        "    \"Naming Conventions\", \"Code Style & Formatting\", \"Code Complexity\", \"Duplication\",\n",
        "    \"Using standard methods\", \"Moving Functionality\", \"Removing Dead Code\", \"Visibility\",\n",
        "    \"Depreciated Functions\", \"Inline Comments\", \"Documentation\", \"Logging\", \"Feature Completeness\",\n",
        "    \"Wrong Location\", \"Variable Initialisation\", \"Logic Error\", \"Comparison Statements\",\n",
        "    \"Function Parameters\", \"Function Calls\", \"Unvalidated Element\", \"Element Type\",\n",
        "    \"Issues with Outside Code\", \"Unhandled Errors/Exceptions\", \"Input Validation\",\n",
        "    \"Compatibility Issues\", \"Security Concerns\", \"Algorithmic Efficiency/Performance\",\n",
        "    \"Data & Resource Management\", \"Execution Time\", \"Network Usage\", \"Test Coverage\",\n",
        "    \"Test Cases\", \"Test Results\", \"Other Test related\", \"Social Communication\",\n",
        "    \"Knowledge Transfer\", \"Understanding\", \"Misc\"\n",
        "]\n",
        "\n",
        "# Filter based on the frequency of categories\n",
        "value_counts = df_cleaned['SingleLabel'].value_counts()\n",
        "categories_to_keep = value_counts[value_counts >= 5].index.tolist()\n",
        "\n",
        "df_cleaned = df_cleaned[df_cleaned['SingleLabel'].isin(categories_to_keep)]\n",
        "print(f\"Size after category filtering: {len(df_cleaned)}\")\n",
        "\n",
        "# Map the labels to their corresponding IDs\n",
        "categories = sorted(categories_to_keep)\n",
        "label_map = {label: i for i, label in enumerate(categories)}\n",
        "df_cleaned['SingleLabelID'] = df_cleaned['SingleLabel'].map(label_map)\n",
        "\n",
        "print(df_cleaned.shape)\n",
        "\n",
        "# Now, split the dataset\n",
        "if not df_cleaned.empty:\n",
        "    X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(\n",
        "        df_cleaned['Comment Body'], df_cleaned['SingleLabelID'], test_size=0.2, random_state=42\n",
        "    )\n",
        "else:\n",
        "    print(\"Cannot split the dataset as it's empty!\")\n",
        "\n",
        "# 2. 使用BERT的tokenizer进行tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_data(texts, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_input_ids, train_attention_masks = tokenize_data(X_train_cleaned)\n",
        "test_input_ids, test_attention_masks = tokenize_data(X_test_cleaned)\n",
        "train_labels = torch.tensor(y_train_cleaned.values).long()\n",
        "test_labels = torch.tensor(y_test_cleaned.values).long()\n",
        "\n",
        "# 3. DataLoader Preparation\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define a custom BERT model\n",
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(768, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
        "        return loss, logits\n",
        "\n",
        "# Set device and move model to the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomBERTModel(num_labels=len(label_map))\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Learning rate scheduler\n",
        "epochs = 20\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * epochs)\n",
        "\n",
        "# Train the model\n",
        "train_accuracies = []\n",
        "test_accuracies = []  # Store test accuracies\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    predictions_train = []\n",
        "    true_labels_train = []\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "    for batch in progress_bar:\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "        model.zero_grad()\n",
        "        loss, logits = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        logits_train = logits.argmax(dim=1).detach().cpu().numpy()\n",
        "        predictions_train.extend(logits_train)\n",
        "        true_labels_train.extend(labels.cpu().numpy())\n",
        "        progress_bar.set_postfix({'loss': total_loss / (epoch + 1)})\n",
        "\n",
        "    train_accuracy = accuracy_score(true_labels_train, predictions_train)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    model.eval()\n",
        "    predictions_test = []\n",
        "    true_labels_test = []\n",
        "    for batch in test_dataloader:\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "        with torch.no_grad():\n",
        "            _, logits = model(input_ids, attention_mask=attention_mask)\n",
        "        logits_test = logits.argmax(dim=1).detach().cpu().numpy()\n",
        "        predictions_test.extend(logits_test)\n",
        "        true_labels_test.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_accuracy = accuracy_score(true_labels_test, predictions_test)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    print(f\"Epoch {epoch+1} - Training loss: {total_loss/len(train_dataloader):.3f}, Training accuracy: {train_accuracy:.2f}, Test accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# Plot training and test accuracies\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, epochs + 1), train_accuracies, label=\"Training Accuracy\")\n",
        "plt.plot(range(1, epochs + 1), test_accuracies, label=\"Test Accuracy\", linestyle='--')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training and Test Accuracy across Epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfwdSzSHF5S3",
        "outputId": "1473be9d-1d61-423e-c3a9-67680c982a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0, 8)\n"
          ]
        }
      ],
      "source": [
        "print(df_cleaned.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfuaQitYANBb",
        "outputId": "4b7d2941-a6a1-42ae-8ff3-1e41c9346ee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'R': 0, 'C': 1, 'V': 2, 'M': 3, 'K': 4, 'S': 5, 'U': 6, 'N': 7, 'L': 8, 'D': 9, 'I': 10, 'E': 11, 'F': 12, 'W': 13, 'O': 14, 'A': 15, 'T': 16}\n"
          ]
        }
      ],
      "source": [
        "print(label_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyqaYHIrcA48",
        "outputId": "387116b6-d8ab-4e49-b93d-6d7bfb1df84e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1: 100%|██████████| 46/46 [00:28<00:00,  1.60it/s, loss=120]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Training loss: 2.599, Training Accuracy: 0.18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 46/46 [00:29<00:00,  1.55it/s, loss=54.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Training loss: 2.353, Training Accuracy: 0.28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 46/46 [00:30<00:00,  1.52it/s, loss=33.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Training loss: 2.177, Training Accuracy: 0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 46/46 [00:30<00:00,  1.53it/s, loss=23.2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 - Training loss: 2.020, Training Accuracy: 0.42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 46/46 [00:30<00:00,  1.53it/s, loss=16.6]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 - Training loss: 1.808, Training Accuracy: 0.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 46/46 [00:30<00:00,  1.52it/s, loss=12.2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 - Training loss: 1.596, Training Accuracy: 0.57\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 46/46 [00:30<00:00,  1.53it/s, loss=9.34]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 - Training loss: 1.421, Training Accuracy: 0.64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 46/46 [00:30<00:00,  1.48it/s, loss=7.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 - Training loss: 1.287, Training Accuracy: 0.68\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 46/46 [00:30<00:00,  1.52it/s, loss=6.22]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 - Training loss: 1.217, Training Accuracy: 0.70\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 46/46 [00:30<00:00,  1.52it/s, loss=5.24]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 - Training loss: 1.140, Training Accuracy: 0.73\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           R       0.00      0.00      0.00         8\n",
            "           C       0.45      0.62      0.52        37\n",
            "           V       0.00      0.00      0.00         2\n",
            "           M       1.00      0.11      0.20         9\n",
            "           K       0.00      0.00      0.00         4\n",
            "           S       0.00      0.00      0.00         6\n",
            "           U       0.47      0.67      0.55        36\n",
            "           N       0.69      0.58      0.63        19\n",
            "           L       0.64      0.47      0.54        15\n",
            "           D       0.33      0.64      0.44        25\n",
            "           I       0.00      0.00      0.00         5\n",
            "           E       0.00      0.00      0.00         3\n",
            "           F       0.00      0.00      0.00         3\n",
            "           W       0.00      0.00      0.00         1\n",
            "           O       0.00      0.00      0.00         2\n",
            "           A       0.00      0.00      0.00         1\n",
            "           T       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.45       181\n",
            "   macro avg       0.21      0.18      0.17       181\n",
            "weighted avg       0.41      0.45      0.40       181\n",
            "\n",
            "Train Accuracy: 0.50\n",
            "Test Accuracy: 0.45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. 数据加载\n",
        "df = pd.read_json(\"HAO_comment_classification.json\")\n",
        "df_cleaned = df.dropna(subset=['Comment Classification'])\n",
        "df_cleaned['SingleLabel'] = df_cleaned['Comment Classification'].apply(lambda x: x[0])\n",
        "\n",
        "label_map = {label: i for i, label in enumerate(df_cleaned['SingleLabel'].unique())}\n",
        "df_cleaned['SingleLabelID'] = df_cleaned['SingleLabel'].map(label_map)\n",
        "\n",
        "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(\n",
        "    df_cleaned['Comment Body'], df_cleaned['SingleLabelID'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2. 使用BERT的tokenizer进行tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_data(texts, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "train_input_ids, train_attention_masks = tokenize_data(X_train_cleaned)\n",
        "test_input_ids, test_attention_masks = tokenize_data(X_test_cleaned)\n",
        "train_labels = torch.tensor(y_train_cleaned.values).long()\n",
        "test_labels = torch.tensor(y_test_cleaned.values).long()\n",
        "\n",
        "# 3. DataLoader Preparation\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# 4. Custom Model Preparation with additional Fully Connected Layers\n",
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(CustomBERTModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(768, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
        "        return loss, logits\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomBERTModel(num_labels=len(label_map))\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Add learning rate scheduler\n",
        "epochs = 10\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * epochs)\n",
        "\n",
        "# 5. Model Training\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_train_preds = 0\n",
        "    total_train_preds = 0\n",
        "\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "    for batch in progress_bar:\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss, logits = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        correct_train_preds += (preds == labels).cpu().numpy().sum()\n",
        "        total_train_preds += len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'loss': total_loss / (epoch + 1)})\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_train_preds / total_train_preds\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    print(f\"Epoch {epoch+1} - Training loss: {avg_train_loss:.3f}, Training Accuracy: {train_accuracy:.2f}\")\n",
        "\n",
        "# 6. Model Evaluation\n",
        "model.eval()\n",
        "predictions = []\n",
        "correct_test_preds = 0\n",
        "total_test_preds = 0\n",
        "for batch in test_dataloader:\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "    labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loss, logits = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "    preds = torch.argmax(logits, dim=1).flatten()\n",
        "    predictions.extend(preds.cpu().numpy())\n",
        "    correct_test_preds += (preds == labels).cpu().numpy().sum()\n",
        "    total_test_preds += len(labels)\n",
        "\n",
        "test_accuracy = correct_test_preds / total_test_preds\n",
        "test_accuracies.append(test_accuracy)\n",
        "\n",
        "# 7. Compute Metrics\n",
        "true_labels_flat = y_test_cleaned.values\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels_flat, predictions, target_names=label_map.keys()))\n",
        "\n",
        "print(f\"Train Accuracy: {np.mean(train_accuracies):.2f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "13rwD5Y9yxOpyFba4Q7xg9zQRd41zt9Zu",
      "authorship_tag": "ABX9TyNn4oxV9WdT8D5mteKjstB9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}